# 📚 Spring - 부하 테스트 기초 지식

> 💡 성능 테스트 할때 필요한 기초 지식입니다.

## 🍋지연시간 (Latency)
* 클라이언트가 요청을 보낸 후 응답을 받기까지 걸린 시간 주로 ms, s 단위 (ms == 1,000분의 1)
* 지연시간은 API 요청 한건당 얼마의 시간 동안 처리되는지 

## 🍊처리량 (Throughput)
* 단위 시간동안 몇건의 요청을 처리할 수 있는가? 주로 TPS단위 (`Transaction Per Second`)
* 어떤 API가 1초 동안 1000개의 API 요청이 들어올 때 1000개의 요청을 문제없이 처리해 낼 수 있다면 이 API의 `Throughput`은 1000 TPS이상이다.
* 처리량은 일정시간 동안 몇건이나 처리할 수 있는지

## 🍇대역폭 (Bandwidth)
* 네트워크가 단위 시간 동안 전송할 수 있는 최대한의 처리량을 의미합니다. 
* 해당 네트워크를 최대한으로 활용했을 때 얼마나 빠른 속도로 많은 데이터를 보낼 수 있는지를 이야기한다. 

## 🍅성능 테스트 목표 
* 성능 테스트는 성능을 측정할 때 **_지연시간_**, **_처리량_**  2가지를 모두 측정해야 합니다.
* 사용자들이 API 요청이 몇 건일 때 사용자들이 불편함을 느끼지 않도록 처리하려면 어는 정도인지 목표를 정하는 시기 입니다.
* EX) 초당 3000개의 요청이 들어올때 99%의 요청이 100ms 미만으로 처리되어야 합니다. 

## 🍍운영체제 
* 운영체제란 컴퓨터의 물리적인 자원을 관리하면서 필요한 곳에 자원을 할당하여 프로세스를 실행하도록 도와주는 역할을 합니다.
* 우리가 서버에 애플리케이션을 배포하면 운영체제는 프로세스라는 존재로 생성해서 관리 합니다.
* 프로세스는 서버가 가지고 있는 CPU, 메모리, 디스크를 할당 받아서 작업을 처리합니다.
> API 요청을 받아서 처리하는 과정에서 CPU, 메모리, 디스크 자원을 사용한다.

작업 마다 CPU가 많이 필요한 작업이 있고 메모리나 디스크를 많이 사용하는 작업도 있습니다. 하지만 이 자원은 절대 무한하지 않습니다. 
성능 테스트에서 이미 많이 사용되고 있다면 해당 자원이 필요한 요청이 왔을 때 처리가 지연될 수 있습니다. 
설령 다른 자원들은 여유가 있다라고 하더라도, 서버에서 해당 자원이 모두 사용 중이면 다른 작업들이 대기 중인 상태가 될 수밖에 없습니다.

즉, 성능 테스트를 할 때 서버가 가지고 있는 자원 중 사용률이 높아지는 자원이 있다면 해당 자원의 사용률을 낮추는 방법을 고민해야 합니다.

## 🍆지연시간, 처리량 증가시 흐름 

* 클라이언트의 요청이 많아지면 초반에는 처리량이 증가합니다. 그러면 점점 서버 자원의 사용량도 증가합니다.
* 사용량이 증가하면 서버에있는 자원을 여러 프로세스와 스레드가 사용하기 위해 대기하는 시간도 길어집니다.
* 다른 프로세스나 스레드가 쓰고 있으니깐 기다림 그러면 한 건을 처리하는 지연시간(`Latency`)이 길어집니다.
* 지연시간이 길어지면 처리되지 못한 요청들이 쌓이다 보면 서버에서 요청 받지 못하거나 처리 시간이 너무 길어져서 클라이언트 측에서 타임아웃으로 처리하는 경우가 생깁니다.

* 경쟁적인 상태란 프로세스와 스레드가 서버 자원을 사용하기 위해 대기하는 시간이 길어지면 이 상황을 경쟁적인 상태라고 표현합니다.
* 경쟁적인 상태가 되면 처치량이 오히려 평소 요청이 적게 들어올 때보다 더 낮아질 수도 있습니다.
* 왜냐하면 요청 하나의 작업을 완료하기 위해서는 CPU, 메모리, 디스크가 모두 사용이 되어야 하는데 서버 자원이 너무 바쁜 상태가 되면 타임아웃이 날수 있습니다.

<img width="775" height="249" alt="Image" src="https://github.com/user-attachments/assets/d85986d1-d2e7-47dd-baa0-e8dd1286b650" />

## 👾네트워크 지연 이란?
네트워크 지연은 클라이언트가 서버에 요청을 보내고 응답을 받기까지 걸리는 시간 중 네트워크 전송에 의해 추가되는 시간입니다.
* 서버가 서울에 있을 때 대구에 요청한 사람은 10ms 걸리고 일본에서 요청한 사람은 30ms가 걸렸습니다.
* 전송 속도는 빛의 속도에 근접하지만, 케이블을 따라 이동해야 하기 때문에 거리가 멀수록 지연 시간이 증가합니다.
* 또한 요청이 단순히 직선으로 가지 않고 여러 라우터, 스위치를 거치면서 지연이 누적됩니다.

그래서 같은 서버에 요청을 보내더라도 대구 사용자가 응답을 더 빨리 받고 일본 사용자는 더 느리게 받는 이유가 바로 네트워크 지연 때문입니다. 

## 🎯데이터베이스 지연시간 이란?
데이터베이스 지연시간 이란 서버 애플리케이션이 DB에 쿼리를 보내고 결과를 받기까지 걸리는 시간 입니다.

데이터베이스도 어플리케이션과 같은 일종이여서 자원을 할당한다. 
* 디스크 : 데이터들이 저장되어있음
* 메모리 : 데이터를 CPU가 연산할 수 있게 준비 혹은 빠르게 처리하기 위해 캐시
* CPU  : 사용자가 원하는 데이터인지 확인

## 📚데이터베이스 지연시간 종류
### 처리량이 많을 때 
* 데이터베이스도 일종의 어플리케이션이여서 많은 요청이 들어올 때 서버의 자원이 부족하면 지연시간이 길어진다.

### 쿼리 처리 시간
* 데이터베이스에 많은 데이터 중 특정 데이터를 찾아내야 하는 경우 지연시간이 길어질 수 있습니다.
* 단순 조회는 빠르지만, 조인, 서브쿼리, 대량의 데이터 조회, 갱신은 시간이 올래 걸림

### 인덱스 사용 여부
* 인덱스가 잘 걸린 컬럼을 조회하면 ms 단위 응답이 가능하지만
* 인덱스가 없으면 풀스캔(`Full Table Scan`)으로 수십~수백 ms 이상 지연 됩니다.

### 트랜잭션, 락과 동시성  
* 여러 트랜잭션이 동시에 같은 데이터를 수정하려 하면 락이 걸려 대기 시간이 발생합니다.
* `UPDATE` 쿼리에서 다른 트랜잭션이 끝나길 기다리는 시간 만큼 지연시간이 발생
* 때로는 데드락이 발생하여 응답이 처리되지 않기도 합니다.

### 한번에 많은 데이터를 응답으로 줘야 할 때 (100MB)
* 대량의 데이터를 한 번에 응답으로 주면, DB는 결과를 메모리에 적재하는데 큰 자원을 사용합니다.
* 또한 DB 와 서버 간 네트워크 대역폭을 장기간 점유하게 됩니다.
* 서버는 이를 받아 메모리에 올려 처리해야 하기 때문에 CPU, 메모리를 많이 소모하게 되고 결과 적으로 다른 요청들의 처리에도 영향을 주어 전체 시스템 성능 저하로 이루어 질 수 있습니다. 

<img width="1536" height="1024" alt="Image" src="https://github.com/user-attachments/assets/1a2368fe-2450-4ffa-9c63-f99d535796e6" />

## 📋스레드 풀, 커넥션 풀
스레드 풀이란 어플리케이션 서버가 요청을 받아서 처리하는 자원입니다.
* 자바에선 Tomcat 같은 어플리케이션 서버를 사용하면 기본적으로 200개의 스레드가 생성됩니다. 이 스레드들은 미리 생성 되어서 요청을 처리한 후에는 다시 반납됩니다.
* 하지만 지연시간이 길어진다면 결국에는 모든 스레드가 사용중인 상태가 되고 일부 요청은 큐(`Queue`)에 저장되지만 큐(`Queue`) 또한 모두 찰 경오 그 이후 요청들은 버려지게 됩니다.
* 그렇다고 이런 문제를 해결한다고 무작정 스레드 숫자를 늘리면 서버에 물리적인 자원이 고갈되고 지나치게 경쟁적인 상태가 발생할 수 있습니다.
* 이런 문제는 로드밸런싱을 하여 여러 서버가 트래픽을 받도록 개선하거나 고정된 스레드 수를 정해두고 요청을 처리하는 방식이 아니라 비동기적으로 요청을 처리하는 방식으로 바꾸는게 좋습니다. 

커넥션 풀이란 애플리케이션과 데이터베이스가 서로 데이터를 주고받는 자원입니다.
* 스레드 풀과 동일하게 미리 생성하두고 재사용을 하며 처리량이 많아지 빠르게 고갈될 수 있습니다.
* 데이터베이스 역시 최대 커넥션 숫자를 제한하는 이유는 커넥션이 많으면 데이터베이스 서버의 자원이 경쟁적인 상태가 될수 있기 때문입니다. 
___
